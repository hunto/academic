
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5.0, minimum-scale=0.2">


<head>
    <script>var clicky_site_ids = clicky_site_ids || []; clicky_site_ids.push(101296995);</script>
    <script async src="//static.getclicky.com/js"></script>    

    <script>
        try{
            if (window.screen.width < 700) {
                setActiveStyleSheet("jemdoc_mobile.css"); 
            } 
            else if(/iPad/i.test(navigator.userAgent)){ 
                setActiveStyleSheet("jemdoc.css"); 
            } 
            else{
                setActiveStyleSheet("jemdoc.css"); 
            } 
        } 
        catch(e){} 

        function setActiveStyleSheet(filename){
            document.write("<link href="+filename+" rel=stylesheet>");
        }

        function checkFilter(type, li) {
            if (type == "All") {
                return true
            }
            else if (type == "First-authored") {
                res = li.getAttribute("first_authored")
                return res
            }
            else {
                cate = li.getAttribute("category")
                if (!cate) {
                    return false
                }
                items = cate.split(',')
                for (j = 0; j < items.length; j++) {
                    console.log(items[j])
                    if (type.toUpperCase() == items[j].toUpperCase()) {
                        return true
                    }
                }
                return false
            }
        }

        function filterPub(type) {
            ul = document.getElementById("publications")
            li = ul.getElementsByTagName("li")
            for (i = 0; i < li.length; i++) {
                if (!checkFilter(type, li[i])) {
                    li[i].style.display = "none";
                }
                else {
                    li[i].style.display = ""
                }
            }
            // change the button color
            bts = document.getElementsByClassName("filter")
            for (k = 0; k < bts.length; k++) {
                if (bts[k].textContent == type) {
                    bts[k].style.setProperty("--color", "#000")
                    bts[k].style.setProperty("--border", "#000")
                    // bts[k].style.color = "#000"
                }
                else {
                    bts[k].style.setProperty("--color", "#a0a0a0")
                    bts[k].style.setProperty("--border", "#d3d3d3")
                    // bts[k].style.color = "#a0a0a0"
                }
            }
        }

    </script>

    <script>
        // import data from './bibtex.json' assert { type: 'json' };
        const data = {
"huang2023masked": `@inproceedings{
huang2023masked,
title={Masked Distillation with Receptive Tokens},
author={Tao Huang and Yuan Zhang and Shan You and Fei Wang and Chen Qian and Jian Cao and Chang Xu},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=mWRngkvIki3}
}`,
"huang2023knowledge": `@inproceedings{huang2023knowledge,
 author = {Huang, Tao and You, Shan and Wang, Fei and Qian, Chen and Xu, Chang},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {33716--33727},
 publisher = {Curran Associates, Inc.},
 title = {Knowledge Distillation from A Stronger Teacher},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/da669dfd3c36c93905a17ddba01eef06-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}`,
"du2022quantum": `@article{du2022quantum,
  title={Quantum circuit architecture search for variational quantum algorithms},
  author={Du, Yuxuan and Huang, Tao and You, Shan and Hsieh, Min-Hsiu and Tao, Dacheng},
  journal={npj Quantum Information},
  volume={8},
  number={1},
  pages={62},
  year={2022},
  publisher={Nature Publishing Group UK London}
}`,
"huang2022greedynasv2": `@inproceedings{huang2022greedynasv2,
  title={Greedynasv2: greedier search with a greedy path filter},
  author={Huang, Tao and You, Shan and Wang, Fei and Qian, Chen and Zhang, Changshui and Wang, Xiaogang and Xu, Chang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11902--11911},
  year={2022}
}`,
"huang2022dyrep": `@inproceedings{huang2022dyrep,
  title={Dyrep: bootstrapping training with dynamic re-parameterization},
  author={Huang, Tao and You, Shan and Zhang, Bohan and Du, Yuxuan and Wang, Fei and Qian, Chen and Xu, Chang},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={588--597},
  year={2022}
}`
        }

        const getBibTex = async (key) => {
            await navigator.clipboard.writeText(data[key]);
            alert("The following text was copied to your clipboard.\n===============\n"+data[key])
            // prompt("You can copy the text manually.", data[key]);
        }
    </script>

    <link rel="shortcut icon" href="myIcon.ico">
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <meta name="keywords" content="Tao Huang, SenseTime">
    <meta name="description" content="Tao Huang's home page">
    <!-- <link rel="stylesheet" href="jemdoc.css" type="text/css" />
    <link rel="stylesheet" media="screen and (max-width:700px)" href="jemdoc_mobile.css" type="text/css" />
    <link rel="stylesheet" media="screen and (max-width:700px)" href="jemdoc.css" type="text/css" /> -->
    <title>Tao Huang - Homepage</title>
</head>

<body>
    <div id="layout-content" style="margin-top:0px">
        <table>
            <tbody>
                <tr>
                    <td width="60%" class="tdw" border="0">
                        <div id="toptitle">
                            <h1>Tao Huang</h1>
				        </div>
                        <p>
                            Ph.D. Student<br>
                            The University of Sydney
                        </p>
                        <p>
                            Email: <a href="mailto:huntocn@gmail.com">huntocn [at] gmail.com</a>
                        </p>
                        <p>
                            <a href="https://github.com/hunto"><img src="assets/github.png" class="icon"></a>&nbsp;&nbsp;
                            <a href="https://scholar.google.com/citations?user=jkcRdBgAAAAJ&hl=en"><img src="assets/google_scholar.png" class="icon"></a>
                        </p>
                        <!-- <b>Control the controllable, observe the observable, leave the rest alone.</b> -->
                    </td>
                    <td width="20%"><img src="assets/taohuang.png" border="0" width="100%"></br></td>
			        
		<tr>
	</tbody>
</table>

<!-- <h2>Biography [<a href="assets/CV_taohuang.pdf">CV</a>]</h2> -->
<h2>Biography</h2>
<p>
    <div style="text-align:justify"> 
        My name is Tao Huang (黄涛). I am a 2nd-year PhD student at <a href="https://www.sydney.edu.au/">The University of Sydney</a>, advised by <a href="http://changxu.xyz">Prof. Chang Xu</a>. 
        <!-- Before that, I was a Researcher at <a href="https://www.sensetime.com">SenseTime</a>, supervised by <a href="https://shanyou92.github.io/">Dr. Shan You</a>.  -->
        In 2020, I received my Bachelor's degree in Computer Science at <a href="http://english.hust.edu.cn/">Huazhong University of Science and Technology</a>, China.
    </div>
</p>
<p>My major research interests lie within model compression algorithms, such as
    <ul>
        <li style="margin-top: 0.2em">Efficient architectures: NAS, pruning, Rep, handcraft</li>
        <li style="margin-top: 0.2em">Knowledge distillation (KD)</li>
    </ul>
</p>

<!-- <p><font color="red">Pinned: </font></p> -->
<h2>News</h2>
<ul>
    <li style="margin-top: 0.2em">[2023/09] One paper (<a href="https://arxiv.org/abs/2305.02722">DiffKD</a>) was accepted to NeurIPS 2023.</li>
    <li style="margin-top: 0.2em">[2023/07] One paper (<a href="https://arxiv.org/abs/2305.02722">AKD</a>) was accepted to ACM MM 2023.</li>
    <li style="margin-top: 0.2em">[2023/05] We released <a href="https://arxiv.org/abs/2305.15712">DiffKD</a> and <a href="https://arxiv.org/abs/2305.02722">AKD</a> at arXiv.</li>
    <li style="margin-top: 0.2em">[2023/01] One paper (<a href="https://arxiv.org/abs/2205.14589">MasKD</a>) was accepted to ICLR 2023.</li>
    <li style="margin-top: 0.2em">[2022/09] One paper (<a href="https://arxiv.org/abs/2205.10536">DIST</a>) was accepted to NeurIPS 2022.</li>
</ul>
<button type="button" class="collapsible">More</button>
    <div class="content">
        <ul>
            <li style="margin-top: 0.2em">[2022/07] We released <a href="https://arxiv.org/abs/2207.05557">LightViT</a> <a href="https://github.com/hunto/LightViT">[code]</a> at arXiv.</li>
            <li style="margin-top: 0.2em">[2022/05] We released <a href="https://arxiv.org/abs/2205.10536">DIST</a> <a href="https://github.com/hunto/DIST_KD">[code]</a> and <a href="https://arxiv.org/abs/2205.14589">MasKD</a> <a href="https://github.com/hunto/MasKD">[code]</a> at arXiv.</li>
            <li style="margin-top: 0.2em">[2022/04] One paper (<a href="https://arxiv.org/abs/2010.10217">QAS</a>) was accepted to <i>Nature Partner Journals</i> Quantum Information (NPJ QI).</li>
            <li style="margin-top: 0.2em">[2022/03] Two papers (<a href="https://arxiv.org/abs/2111.12609">GreedyNASv2</a> & <a href="https://arxiv.org/abs/2203.12868">DyRep</a>) were accepted to CVPR 2022.</li>
            <li style="margin-top: 0.2em">[2022/01] One paper (<a href="https://arxiv.org/abs/2202.13197">ReLoss</a>) was accepted to ICLR 2022.</li>
            <li style="margin-top: 0.2em">
                [2021/12] We released <ax href="https://github.com/open-mmlab/mmrazor">MMRazor</ax> - a model compression toolkit for model slimming and AutoML, which includes 3 mainstream technologies NAS, pruning, and KD. MMRazor can be easily applied to various projects (e.g., MMDet and MMCls) in OpenMMLab.
            </li>
            <li style="margin-top: 0.2em">
                [2021/11] We released GreedyNASv2 at <ax href="https://arxiv.org/abs/2111.12609">arXiv</a>.
            </li>
            <li style="margin-top: 0.2em">
                [2021/03] One paper about NAS was accepted to CVPR 2021. The NAS benchmark in our paper was released at <ax href="https://github.com/xiusu/NAS-Bench-Macro">github</a>.
            </li>
            <li style="margin-top: 0.2em">
                [2021/01] One paper about channel number search (pruning) was accepted to ICLR 2021 as spotlight.
            </li>
            <li style="margin-top: 0.2em">
                [2020/11] One paper about NAS was released at <ax href="https://arxiv.org/abs/2011.09300">arXiv</a>. Our TopoNAS explicitly learns the topology for differentiable NAS (DARTS), and enjoys significant efficiency improvement on obtained architectures.
            </li>
            <li style="margin-top: 0.2em">
                [2020/10] One paper about quantum architecture search (QAS) was released at <ax href="https://arxiv.org/abs/2010.10217">arXiv</a>. Our QAS implicitly learns a rule that can well suppress the influence of quantum noise and the barren plateau.
            </li>
            <li style="margin-top: 0.2em">
                [2020/02] One paper about NAS was accepted to CVPR 2020.
            </li>
        </ul>
    </div>

<!-- <h2>Publications [<a href="https://scholar.google.com/citations?user=jkcRdBgAAAAJ&hl=en">Google Scholar</a>]</h2> -->
<h2>Publications</h2>
*: equal contribution.<br>
First-authored papers: <venue>CVPR</venue>x 4, <venue>NeurIPS</venue>x 1, <venue>ICLR</venue>x 2 <br><br>

<button class="filter" type="button" onclick="filterPub('All')" style="--color: #000; --border: #000">All</button>&nbsp;
<button class="filter" type="button" onclick="filterPub('First-authored')">First-authored</button>&nbsp;
<button class="filter" type="button" onclick="filterPub('KD')">KD</button>&nbsp;
<button class="filter" type="button" onclick="filterPub('NAS')">NAS</button>&nbsp;
<button class="filter" type="button" onclick="filterPub('Pruning')">Pruning</button>

<ul id="publications">
    <li first_authored=true category="KD">
        <venue>NeurIPS</venue><pt>Knowledge Diffusion for Distillation</pt><br>
        <b>Tao Huang</b><g>, Yuan Zhang, Mingkai Zheng, Shan You, Fei Wang, Chen Qian, Chang Xu</g><br>
        <em>Advances in Neural Information Processing Systems</em> (<b>NeurIPS</b>), 2023.</em>
        <p>
            <a href="https://arxiv.org/abs/2305.15712" class="button-59">ArXiv</a>
            <a href="https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=4615443208731882220" class="button-59">Bib</a>
            <a href="https://github.com/hunto/DiffKD">
            <img alt="" src="https://img.shields.io/github/stars/hunto/DiffKD?style=social" style="vertical-align: bottom; height: 1.2rem;"></a>
        </p>
    </li>
    <li category="KD">
        <venue>ACM MM</venue><pt>Avatar Knowledge Distillation: Self-ensemble Teacher Paradigm with Uncertainty</pt><br>
        <g>Yuan Zhang, Weihua Chen, Yichen Lu,</g> <b>Tao Huang</b><g>, Xiuyu Sun, Jian Cao</g><br>
        <em>Proceedings of the 31th ACM International Conference on Multimedia</em> (<b>ACM MM</b>), 2023.
        <p>
            <a href="https://arxiv.org/abs/2305.02722" class="button-59">ArXiv</a>
            <a href="https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=9322121606680381236" class="button-59">Bib</a>
            <a href="https://github.com/Gumpest/AvatarKD">
            <img alt="" src="https://img.shields.io/github/stars/Gumpest/AvatarKD?style=social" style="vertical-align: bottom; height: 1.2rem;"></a>
        </p>
    </li>
    <li first_authored=true category="KD">
		<venue>ICLR</venue><pt>Masked Distillation with Receptive Tokens</pt><br>
		<b>Tao Huang</b>*<g>, Yuan Zhang*, Shan You, Fei Wang, Chen Qian, Jian Cao, Chang Xu</g><br>
		<em>International Conference on Learning Representations</em> (<b>ICLR</b>), 2023.</em>
		<p>
			<a class="button-59" href="https://arxiv.org/abs/2205.14589">ArXiv</a>
            <button class="button-59" onclick="getBibTex('huang2023masked')">Bib</button>
            <a href="https://github.com/hunto/MasKD">
            <img alt="" src="https://img.shields.io/github/stars/hunto/MasKD?style=social" style="vertical-align: bottom; height: 1.2rem;"></a>
		</p>
    </li>
    <li first_authored=true category="KD">
		<venue>NeurIPS</venue><pt>Knowledge Distillation from A Stronger Teacher</pt><br>
		<b>Tao Huang</b><g>, Shan You, Fei Wang, Chen Qian, Chang Xu</g><br>
        <em>Advances in Neural Information Processing Systems</em> (<b>NeurIPS</b>), 2022.
		<p>
			<a href="https://arxiv.org/abs/2205.10536" class="button-59">ArXiv</a>
			<button class="button-59" onclick="getBibTex('huang2023knowledge')">Bib</button>
            <a href="assets/dist/KD_sharing_Tao_20220715.pdf" class="button-59">Slides</a>
            <a href="assets/dist/NeurIPS2022_DIST_poster.pdf" class="button-59">Poster</a>
            <a href="https://mp.weixin.qq.com/s/PwzyaZXCrl_W8NmiQgXm0g" class="button-59">解读</a>
            <a href="https://github.com/hunto/DIST_KD">
                <img alt="" src="https://img.shields.io/github/stars/hunto/DIST_KD?style=social" style="vertical-align: bottom; height: 1.2rem;">
            </a>
		</p>
    </li>
    <li category="NAS">
		<venue>NPJ QI</venue><pt></pt><pt>Quantum circuit architecture search for variational quantum algorithms</pt><br>
		<g>Yuxuan Du,</g> <b>Tao Huang</b><g>, Shan You, Min-Hsiu Hsieh, Dacheng Tao</g><br>
		<em>Nature Partner Journals Quantum Information</em> (<b>NPJ QI</b>), 2022.<br>
		<p>
			<a href="https://arxiv.org/abs/2010.10217" class="button-59">ArXiv</a>
            <button class="button-59" onclick="getBibTex('du2022quantum')">Bib</button>
			<!-- <a href="https://scholar.google.com/scholar?cluster=14041544508923660633&hl=en&as_sdt=0,5" class="button-59">Bib</a> -->
			<a href="https://github.com/yuxuan-du/Quantum_architecture_search">
            <img alt="" src="https://img.shields.io/github/stars/yuxuan-du/Quantum_architecture_search?style=social" style="vertical-align: bottom; height: 1.2rem;">
            </a>
        </p>
    </li>
    <li first_authored=true category="NAS">
		<venue>CVPR</venue><pt></pt><pt>GreedyNASv2: Greedier Search with a Greedy Path Filter</pt><br>
		<b>Tao Huang</b><g>, Shan You, Fei Wang, Chen Qian, Changshui Zhang, Xiaogang Wang, Chang Xu</g><br>
		<em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2022.<br>
		<p>
			<a href="https://arxiv.org/abs/2111.12609" class="button-59">ArXiv</a>
			<!-- <a href="https://scholar.google.com/scholar?cluster=8646649449956447640&hl=en&as_sdt=0,5" class="button-59">Bib</a> -->
            <button class="button-59" onclick="getBibTex('huang2022greedynasv2')">Bib</button>
            <a href="assets/greedynasv2/CVPR2022_GreedyNASv2_Poster.pdf" class="button-59">Poster</a>
		</p>
    </li>
    <li first_authored=true>
        <venue>CVPR</venue><pt>DyRep: Bootstrapping Training with Dynamic Re-parameterization</pt><br>
        <b>Tao Huang</b><g>, Shan You, Bohan Zhang, Yuxuan Du, Fei Wang, Chen Qian, Chang Xu</g><br>
        <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2022.<br>
        <p>
            <a href="https://arxiv.org/abs/2203.12868" class="button-59">ArXiv</a>
            <!-- <a href="https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=9004725926464672087" class="button-59">Bib</a> -->
            <button class="button-59" onclick="getBibTex('huang2022dyrep')">Bib</button>
            <a href="assets/dyrep/CVPR2022_DyRep_Poster.pdf" class="button-59">Poster</a>
            <a href="https://github.com/hunto/DyRep"><img alt="" src="https://img.shields.io/github/stars/hunto/DyRep?style=social" style="vertical-align: bottom; height: 1.2rem;"></a>
		</p>
    </li>
    <li first_authored=true>
        <venue>ICLR</venue><pt>Relational Surrogate Loss Learning</pt><br>
        <b>Tao Huang</b><g>, Zekang Li, Hua Lu, Yong Shan, Shusheng Yang, Yang Feng, Fei Wang, Shan You, Chang Xu</g><br>
        <em>International Conference on Learning Representations</em> (<b>ICLR</b>), 2022.<br>
        <p>
			<a href="https://arxiv.org/abs/2202.13197" class="button-59">ArXiv</a>
            <a href="https://openreview.net/forum?id=dZPgfwaTaXv" class="button-59">Bib</a>
            <a href="assets/reloss/Poster_ICLR2022_ReLoss.pdf" class="button-59">Poster</a>
            <a href="assets/reloss/Slides_ICLR2022_ReLoss.pdf" class="button-59">Slides</a>
            <a href="https://github.com/hunto/ReLoss"><img alt="" src="https://img.shields.io/github/stars/hunto/ReLoss?style=social" style="vertical-align: bottom; height: 1.2rem;"></a>
            
		</p>
    </li>
    <li category="pruning">
		<venue>ICASSP</venue><pt>Data Agnostic Filter Gating for Efficient Deep Networks</pt><br>
        <g>Hongyan Xu, Xiu Su, Shan You,</g> <b>Tao Huang</b><g>, Fei Wang, Chen Qian, Changshui Zhang, Chang Xu, Dadong Wang, Arcot Sowmya</g><br>
		<em>IEEE International Conference on Acoustics, Speech and Signal Processing</em> (<b>ICASSP</b>), 2022.
		<p>
			<a href="https://arxiv.org/abs/2010.15041" class="button-59">ArXiv</a>
			<a href="https://scholar.google.com/scholar?cluster=6802250960153223046&hl=en&as_sdt=0,5" class="button-59">Bib</a>
		</p>
	</li>
    <li first_authored=true category="NAS">
        <venue>CVPR</venue><pt>Prioritized Architecture Sampling with Monto-Carlo Tree Search</pt><br>
        <g>Xiu Su*,</g> <b>Tao Huang</b>*<g>, Yanxi Li, Shan You, Fei Wang, Chen Qian, Changshui Zhang, Chang Xu</g><br>
        <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2021.<br>
        <p>
			<a href="https://arxiv.org/abs/2103.11922" class="button-59">ArXiv</a>
            <a href="assets/mctnas/Poster_CVPR2021_MCT-NAS.pdf" class="button-59">Poster</a>
            <a href="https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=16897259555170724856" class="button-59">Bib</a>
            <a href="https://github.com/xiusu/NAS-Bench-Macro" class="button-59">NAS-Bench-Macro</a>
            <img alt="" src="https://img.shields.io/github/stars/xiusu/NAS-Bench-Macro?style=social" style="vertical-align: bottom; height: 1.2rem;">
		</p>
    </li>
    <li category="NAS,pruning">
        <venue>ICLR</venue><pt>Locally Free Weight Sharing for Network Width Search</pt><br>
        <g>Xiu Su, Shan You,</g> <b>Tao Huang</b><g>, Fei Wang, Chen Qian, Changshui Zhang, Chang Xu</g><br>
        <em>International Conference on Learning Representations</em> (<b>ICLR, Spotlight</b>), 2021.<br>
        <p>
			<a href="https://arxiv.org/abs/2102.05258" class="button-59">ArXiv</a>
            <a href="https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=13852905600525060682" class="button-59">Bib</a>
            <a href="https://openreview.net/forum?id=S0UdquAnr9k" class="button-59">OpenReview</a>
		</p>
    </li>
	<li first_authored=true category="NAS">
		<venue>CVPR</venue><pt>GreedyNAS: Towards Fast One-Shot NAS with Greedy Supernet</pt><br>
        <g>Shan You*,</g> <b>Tao Huang</b>*<g>, Mingmin Yang*, Fei Wang, Chen Qian, Changshui Zhang</g><br>
		<em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2020.</br>
		<p>
			<a href="https://arxiv.org/abs/2003.11236" class="button-59">ArXiv</a>
            <a href="https://scholar.google.com/scholar?cluster=11467412928038806592&hl=en&as_sdt=0,5" class="button-59">Bib</a>
            <a href="assets/greedynas/Poster_CVPR2020_GreedyNAS.pdf" class="button-59">Poster</a>
            <a href="assets/greedynas/Video_CVPR2020_GreedyNAS.mp4" class="button-59">Video</a>
            <a href="assets/greedynas/Slides_GreedyNAS_titan.pdf" class="button-59">Slides</a>
            <a href="https://github.com/open-mmlab/mmrazor">
            <img alt="" src="https://img.shields.io/github/stars/open-mmlab/mmrazor?style=social" style="vertical-align: bottom; height: 1.2rem;"></a>
		</p>
	</li>
</ul>

<h2>Manuscripts</h2>
<ul>
    <li>
        <venue>arXiv</venue><pt>Positive Label Is All You Need for Multi-Label Classification</pt><br>
        <g>Zhixiang Yuan, Kaixin Zhang, </g><b>Tao Huang</b><br>
        <em>arXiv preprint arXiv:2306.16016 (2023).</em>
        <p>
            <a href="https://arxiv.org/abs/2306.16016" class="button-59">ArXiv</a>
            <a href="https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=11695637510257123983" class="button-59">Bib</a>
        </p>
    </li>
    <li>
        <venue>arXiv</venue><pt>LightViT: Towards Light-Weight Convolution-Free Vision Transformers</pt><br>
        <b>Tao Huang</b><g>, Lang Huang, Shan You, Fei Wang, Chen Qian, Chang Xu</g><br>
        <em>arXiv preprint arXiv:2207.05557 (2022).</em>
        <p>
            <a href="https://arxiv.org/abs/2207.05557" class="button-59">ArXiv</a>
            <a href="https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=13876321258274905912" class="button-59">Bib</a>
            <a href="https://github.com/hunto/LightViT">
            <img alt="" src="https://img.shields.io/github/stars/hunto/DiffKD?style=social" style="vertical-align: bottom; height: 1.2rem;"></a>
        </p>
    </li>
    <li>
		<venue>arXiv</venue><pt>Explicitly Learning Topology for Differentiable Neural Architecture Search</pt><br>
		<b>Tao Huang</b><g>, Shan You, Yibo Yang, Zhuozhuo Tu, Fei Wang, Chen Qian, Changshui Zhang</g><br>
		<em>arXiv preprint arXiv:2011.09300 (2020).</em>
		<p>
			<a href="https://arxiv.org/abs/2011.09300" class="button-59">ArXiv</a>
			<a href="https://scholar.google.com/scholar?cluster=239245335818813796&hl=en&as_sdt=0,5" class="button-59">Bib</a>
		</p>
    </li>
</ul>

<!-- <h2>Manuscripts [<a href="https://scholar.google.com/citations?user=jkcRdBgAAAAJ&hl=en">Google Scholar</a>]</h2> -->
<!-- <h2>Manuscripts</h2> -->
<!-- <ul> -->
    <!-- <li>
		<pt>Explicitly Learning Topology for Differentiable Neural Architecture Search</pt><br>
		<b>Tao Huang</b>, Shan You, Yibo Yang, Zhuozhuo Tu, Fei Wang, Chen Qian, Changshui Zhang<br>
		<em>arXiv preprint arXiv:2011.09300 (2020).</em>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/abs/2011.09300">ArXiv</a>]
			[<a href="https://scholar.google.com/scholar?cluster=239245335818813796&hl=en&as_sdt=0,5">Bib</a>]
		</p>
    </li> -->
<!-- </ul> -->

<h2>Academic Services</h2>
<b>Reviewer for Conferences:</b>
<ul>
    <li style="margin-top: 0.2em">
        Neural Information Processing Systems (<b>NeurIPS</b>), 2021-2023.
    </li>
    <li style="margin-top: 0.2em">
        International Conference on Learning Representations (<b>ICLR</b>), 2023.
    </li>
    <li style="margin-top: 0.2em">
        International Conference on Machine Learning (<b>ICML</b>), 2022-2023.
    </li>
    <li style="margin-top: 0.2em">
        Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2022-2023.
    </li>
    <li style="margin-top: 0.2em">
        International Conference on Computer Vision (<b>ICCV</b>), 2023.
    </li>
    <li style="margin-top: 0.2em">
        AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2023-2024.
    </li>
    <li style="margin-top: 0.2em">
        ACM International Conference on Multimedia (<b>ACM MM</b>), 2021-2023.
    </li>
</ul>

<b>Reviewer for Journals:</b>
<ul>
    <li style="margin-top: 0.2em">
        IEEE Transactions on Neural Networks and Learning Systems (<b>TNNLS</b>)
    </li>
    <li style="margin-top: 0.2em">
        IEEE Transactions on Image Processing (<b>TIP</b>)
    </li>
</ul>

<h2>Talks</h2>
<ul>
    <li>TMLR Young Scientist Seminar@HKBU: "Knowledge Distillation from A Stronger Teacher", Jul. 2022. [<a href="assets/dist/KD_sharing_Tao_20220715.pdf">Slides</a>]</li>
</ul>

<h2>Education</h2>
<ul>
    <li>
        <div style="display: flex; justify-content: space-between;">
            <div><a href="https://www.sydney.edu.au/">The University of Sydney</a>, Sydney, Australia</div>
            <div style="margin-left: 2px;">July. 2022 – Present</div>
        </div>
        Ph.D. student at School of Computer Science<br>
        Advisor: <a href="http://changxu.xyz">Prof. Chang Xu</a><br>
    </li>
    <li>
        <div style="display: flex; justify-content: space-between;">
            <div><a href="https://www.hust.edu.cn">Huazhong University of Science and Technology</a>, Wuhan, China</div>
            <div style="margin-left: 2px;">Sep. 2016 – Jun. 2020</div>
        </div>
        B.E. in Computer Science and Technology<br>
    </li>
</ul>

<h2>Selected Experience</h2>
<ul>
	<!-- <li>
        <a href="https://sensetime.com">SenseTime</a>, Beijing, China<br>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>Research Intern</div>
            <div style="margin-left: 2px;">Jul. 2022 - Present</div>
        </div>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>Researcher</div>
            <div style="margin-left: 2px;">Jul. 2020 – Jun. 2022</div>
        </div>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>Research Intern</div>
            <div style="margin-left: 2px;">Aug. 2019 – Jul. 2020</div>
        </div>
        <ul>
            <li style="margin-top: 0.2em">
                Research on model compression algorithms (NAS, KD, pruning, etc.).
            </li>
            <li style="margin-top: 0.2em">
                Research and development on auto-driving (smart carbin) scenes such as face verification and drowsiness detection.
            </li>
            <li style="margin-top: 0.2em">
                Applied NAS to face verification task on large­scale industrial datasets, which significantly improves the performance.
            </li>
        </ul>
	</li>
	<li>
        <a href="https://horizon.ai">Horizon Robotics</a>, Beijing, China
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>Computer Vision Research Intern</div>
            <div style="margin-left: 2px;">May 2019 – Aug. 2019</div>
        </div>
        <ul>
            <li style="margin-top: 0.2em">
                Development on object detection framework: anchor-­free detection method, detection in traffic scene.
            </li>
            <li style="margin-top: 0.2em">
                Research on knowledge distillation methods for face alignment, object detection.
            </li>
        </ul>
	</li> -->
	<li>
        <a href="http://dian.org.cn/">Dian Group</a>, Wuhan, Hubei province, China<br>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>Team Leader of Real­time Face Detection & Alignment Project, AI Group</div>
            <div style="margin-left: 2px;">Nov. 2018 – May 2019</div>
        </div>
        <ul>
            <li style="margin-top: 0.2em">
                Develop Android APP to inference face detection, tracking, and 106-­point landmark models on mobile devices. 
            </li>
            <li style="margin-top: 0.2em">
                Research on model acceleration (e.g., knowledge distillation, model pruning) and facial landmark (e.g., multi­task learning, loss function, augmentation).
            </li>
            <li style="margin-top: 0.2em">
                Our proposed model archieves an inference speed of 5 ms / image on Huawei Mate20 Pro.
            </li>
        </ul>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>Core Member of Beibei Intelligent Customer Service Project, AI Group</div>
            <div style="margin-left: 2px;">Feb. 2018 – Nov. 2018</div>
        </div>
        <ul>
            <li style="margin-top: 0.2em">
                This project comes from <a href="https://www.beibei.com/">Beibei Group Company</a>, Beibei is the bigest mother-­baby ecommerce platform in China. The task is to find optimal answers based on classifications of customer questions.
            </li>
            <li style="margin-top: 0.2em">
                Research and development on text classification and data augmentation, etc.
            </li>
        </ul>
	</li>
	<li>
        3D Printer Team, Wuhan, Hubei province, China
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>Group Learder of Embedded Control Group</div>
            <div style="margin-left: 2px;">Oct. 2016 – Jan. 2019</div>
        </div>
		Topic: developing control algorithms for 3DP/FDM 3D printers<br>
	</li>
</ul>


<h2>Selected Awards</h2>
<ul>
    <li>
        <div style="display: flex; justify-content: space-between;">
            <div>Outstanding Graduate award, Huazhong University of Science and Technology</div>
            <div style="margin-left: 2px;">Jun. 2020</div>
        </div>
    </li>
    <li>
        <div style="display: flex; justify-content: space-between;">
            <div>Outstanding Graduate Thesis award, Huazhong University of Science and Technology</div>
            <div style="margin-left: 2px;">Jun. 2020</div>
        </div>
    </li>
    <!-- <li>
        <div style="display: flex; justify-content: space-between;">
            <div>First Class Prize, National College Student Connected Smarter System Innovation Competition, National</div>
            <div style="margin-left: 2px;">2018</div>
        </div>
    </li>
    <li>
        <div style="display: flex; justify-content: space-between;">
            <div>Third Class Prize, "Challenge Cup" Competition, Provincial</div>
            <div style="margin-left: 2px;">2018</div>
        </div>
    </li>
    <li>
        <div style="display: flex; justify-content: space-between;">
            <div>First Class Prize, "Challenge Cup" Competition, HUST</div>
            <div style="margin-left: 2px;">2018</div>
        </div>
    </li> -->
</ul>

<div id="footer">
	<div id="footer-text" style="text-align: center;">© Tao Huang | Last updated: July 6, 2023</div>
</div>
	<!-- <center>© Tao Huang | Last updated: 02/19/2021</center> -->
    <!--<center>© Tao Huang
    	<script type="text/javascript" language="javascript">
    	if (Date.parse(document.lastModified) != 0) document.write(" | Last updated: " + document.lastModified);</script>
    </center>-->
</div>

</body>

<script>
    var coll = document.getElementsByClassName("collapsible");
    var i;

    for (i = 0; i < coll.length; i++) {
        coll[i].addEventListener("click", function() {
            this.classList.toggle("active");
            var content = this.nextElementSibling;
            if (content.style.display === "block") {
            content.style.display = "none";
            } else {
            content.style.display = "block";
            }
        });
    }
</script>

</html>

